# -*- coding: utf-8 -*-
"""Devices Price Classification Systemipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1u-6d-CgcHsQfYP7yPZF6ZU6S7_gWjfmU
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier

df=pd.read_csv("/content/train - train.csv")


df

df.describe()

df.isna().sum()

df = df.dropna()

df

plt.figure(figsize=(10, 8))
sns.heatmap(df.corr(), annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation Heatmap')
plt.show()

import matplotlib.pyplot as plt

value_counts = df['price_range'].value_counts()

label_map = {0: 'Very high cost', 1: 'High cost', 2: 'Medium cost', 3: 'Low cost'}
labels = [label_map[i] for i in value_counts.index]

plt.bar(labels, value_counts)


plt.show()

X = df.drop('price_range', axis=1)
y = df['price_range']

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y,random_state = 55)

from sklearn.preprocessing import StandardScaler

sc = StandardScaler()
sc.fit(X_train)
X_train_std = sc.transform(X_train)
X_test_std = sc.transform(X_test)

min_samples_split_list = [2,10, 30, 50, 100, 200, 300, 700]  ## If the number is an integer, then it is the actual quantity of samples,
                                             ## If it is a float, then it is the percentage of the dataset
max_depth_list = [2, 4, 8, 16, 32, 64, None]
n_estimators_list = [10,50,100,500]



import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

def plot_accuracy(train_accuracy, test_accuracy, parameter_values, parameter_name):
    plt.title('Train vs Test Accuracy')
    plt.xlabel(parameter_name)
    plt.ylabel('Accuracy')
    plt.xticks(ticks=range(len(parameter_values)), labels=parameter_values)
    plt.plot(train_accuracy, label='Train')
    plt.plot(test_accuracy, label='Test')
    plt.legend()
    plt.show()

def evaluate_model(X_train_std, X_test_std, y_train, y_test, parameter_values, parameter_name):
    train_accuracy = []
    test_accuracy = []
    for param_value in parameter_values:
        model = RandomForestClassifier(**{parameter_name: param_value}, random_state=55).fit(X_train_std, y_train)
        predictions_train = model.predict(X_train_std)
        predictions_test = model.predict(X_test_std)
        accuracy_train = accuracy_score(predictions_train, y_train)
        accuracy_test = accuracy_score(predictions_test, y_test)
        train_accuracy.append(accuracy_train)
        test_accuracy.append(accuracy_test)
    plot_accuracy(train_accuracy, test_accuracy, parameter_values, parameter_name)

# Example usage
min_samples_split_list = [2, 5, 10]
max_depth_list = [None, 5, 10]
n_estimators_list = [50, 100, 200]

evaluate_model(X_train_std, X_test_std, y_train, y_test, min_samples_split_list, 'min_samples_split')
evaluate_model(X_train_std, X_test_std, y_train, y_test, max_depth_list, 'max_depth')
evaluate_model(X_train_std, X_test_std, y_train, y_test, n_estimators_list, 'n_estimators')

random_forest_model = RandomForestClassifier(n_estimators = 200,
                                             max_depth = 10,
                                             min_samples_split = 10)
random_forest_model.fit(X_train_std,y_train)

y_pred_train = random_forest_model.predict(X_train_std)
print('Accuracy Train : %.3f' % accuracy_score(y_train, y_pred_train))

y_pred = random_forest_model.predict(X_test_std)
print('Accuracy test : %.3f' % accuracy_score(y_test, y_pred))

from sklearn.metrics import confusion_matrix,classification_report
cm = confusion_matrix(y_test, y_pred)
print(classification_report(y_test, y_pred))

sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')

